Hand & Eye Controlled Computer Interaction Toolkit
This project is a Python-based toolkit that uses OpenCV, MediaPipe, and PyAutoGUI to control your computer using hand gestures, facial landmarks, and eye movement â€” powered by a simple Tkinter GUI.

Ideal for touchless interaction demos, accessibility research, or gesture-based automation tools.

ğŸ’¡ Features
ğŸ“¢ Hand Gesture Volume Control

Controls system volume using distance between thumb and index finger.

Moves volume up/down based on gesture spread.

ğŸ–±ï¸ Virtual Mouse Control

Index finger moves mouse cursor.

Clicking by bringing thumb close to index finger.

ğŸ‘ï¸ Eye-Controlled Mouse

Moves the mouse cursor using eye tracking.

Performs mouse click on blink detection.

ğŸ“¸ Photo Capture

Automatically captures a photo after 50 frames from webcam.

Saves image as captured_photo.jpg and displays it.

ğŸ› ï¸ Technologies Used
OpenCV

MediaPipe

PyAutoGUI

Pillow

Tkinter (GUI)

ğŸ“¦ Installation
Clone the repository:

bash
Copy
Edit
git clone https://github.com/yourusername/gesture-eye-control.git
cd gesture-eye-control
Install the dependencies:

bash
Copy
Edit
pip install opencv-python mediapipe pyautogui pillow
Note: PyAutoGUI might require additional setup for screen control on macOS or Linux.

ğŸš€ Usage
Run the main script:

bash
Copy
Edit
python your_script_name.py
A simple GUI will appear with four buttons:

Volume Control â†’ Hand-based volume control.

Virtual Mouse Control â†’ Control mouse with finger gestures.

Eye-Controlled Mouse â†’ Move cursor and click using eye movement.

Capture Photo â†’ Takes and displays a webcam photo after a delay.

Press ESC in any OpenCV window to stop that operation.

ğŸ“· Screenshots (Optional)
Add screenshots here to demonstrate each feature visually.

ğŸ‘¨â€ğŸ’» Contributing
Feel free to open Issues or Pull Requests for improvements, bug fixes, or feature suggestions.

ğŸ“ License
This project is licensed under the MIT License.

ğŸ™Œ Acknowledgments
MediaPipe by Google

OpenCV Library

PyAutoGUI Docs

